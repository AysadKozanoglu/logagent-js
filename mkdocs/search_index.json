{
    "docs": [
        {
            "location": "/", 
            "text": "- \nread more\n\n\nlogagent-js\n\n\nSmart and lightweight Log Parser and Log Shipper written in Node. It can ship logs to Elasticsearch and thus also to \nLogsene\n. See \nDocumentation\n.\n\n\nFeatures\n\n\nThis project contains a library and patterns for log parsing and cli tools and installers to use logagent-js as log shipper with the following features: \n\n\nParser\n\n\n\n\nlog format detection and intelligent pattern matching \n\n\npattern library included \n\n\neasy to extend with custom patterns and JS transform functions\n\n\nrecognition of Date and Number fields\n\n\nreplace sensitive data with SHA-1 hash codes\n\n\nGeoIP lookup with automatic GeoIP db updates (maxmind geopip-lite files)\n\n\n\n\nCommand Line Tool\n\n\n\n\nlog format converter (e.g. text to JSON, line delimited JSON or YAML)\n\n\n\n\nlog shipper for \nLogsene\n\n\n\n\n\n\nincluding cli, launchd (Mac OS X), upstart and systemd (Linux) service installer\n\n\n\n\ndisk buffer for failed inserts during network outage\n\n\n\n\nInputs\n\n\n\n\nStandard input (stdin) that can read the output stream from any Linux cli tool\n\n\npatterns are applied to each incoming text line; includes support for multi-line patters, e.g. for Java Stack Traces and JSON input.\n\n\nSyslog Server (UDP) listener - logagent-js can also act as a syslog server and receive Syslog messages via UDP. The parser is applied to the message field. \n\n\nHeroku Log Drain\n makes it easy to ship Heroku logs to Elasticsearch or \nLogsene\n\n\nCloud Foundry Log Drain\n\n\n\n\nProcessing\n\n\n\n\nlogagent-js applies patterns defined in patterns.yml to all logs and creates structured logs from plain-text log lines\n\n\nGeoIP lookups for IP address fields, including automatic download and update of the GeoIP lite database from Maxmind\n\n\n\n\nReliable log shipping with disk buffer\n\n\nLogagent doesn't lose data.  It stores parsed logs to a disk buffer if the network connection to the Elasticsearch API fails.  Logagent retries shipping logs later, when the network or Elasticsearch is available again.  \n\n\nOutputs\n\n\n\n\nbulk inserts to \nLogsene\n / Elasticsearch API\n\n\nJSON, line delimited JSON and YML to standard output  \n\n\n\n\nDeployment options\n\n\n\n\nDeployable as a system service: systemd, upstart (Linux), or launchd (Mac OS X)\n\n\nDocker Container to receive logs via syslog\n\n\nDeployement to Heroku as Heroku Log drain\n\n\nDeployement to Cloud Foundry as Cloud Foundry Log drain (thus usable with Pivotal, Bluemix, etc.)\n\n\n\n\nAPI\n\n\n\n\nNode.js module to integrate parsers into Node.js programs\n\n\nlogagent-js is a part of \nSPM for Docker\n to parse Container Logs\n\n\n\n\nRelated packages\n\n\n\n\nSematext Agent for Docker\n - collects metrics, events and logs from Docker API and CoreOS. Logagent-js is a component of sematext-agent-docker. More Information: \nInnovative Docker Log Management\n\n\nLogsene-CLI\n - Enables searching Logsene log entries from the command-line. \n\n\nSPM Agent for Node.js\n - collects performance metrics for Node and io.js applications\n\n\nCustom Metrics\n - Custom Metrics for SPM \n\n\nWinston-Logsene\n - Logging for Node.js - Winston transport layer for Logsene\n\n\n\n\nSupport\n\n\n\n\nTwitter: \n@sematext\n\n\nBlog: \nsematext.com/blog\n\n\nHomepage: \nsematext.com", 
            "title": "Features and Overview"
        }, 
        {
            "location": "/#logagent-js", 
            "text": "Smart and lightweight Log Parser and Log Shipper written in Node. It can ship logs to Elasticsearch and thus also to  Logsene . See  Documentation .", 
            "title": "logagent-js"
        }, 
        {
            "location": "/#features", 
            "text": "This project contains a library and patterns for log parsing and cli tools and installers to use logagent-js as log shipper with the following features:", 
            "title": "Features"
        }, 
        {
            "location": "/#parser", 
            "text": "log format detection and intelligent pattern matching   pattern library included   easy to extend with custom patterns and JS transform functions  recognition of Date and Number fields  replace sensitive data with SHA-1 hash codes  GeoIP lookup with automatic GeoIP db updates (maxmind geopip-lite files)", 
            "title": "Parser"
        }, 
        {
            "location": "/#command-line-tool", 
            "text": "log format converter (e.g. text to JSON, line delimited JSON or YAML)   log shipper for  Logsene    including cli, launchd (Mac OS X), upstart and systemd (Linux) service installer   disk buffer for failed inserts during network outage", 
            "title": "Command Line Tool"
        }, 
        {
            "location": "/#inputs", 
            "text": "Standard input (stdin) that can read the output stream from any Linux cli tool  patterns are applied to each incoming text line; includes support for multi-line patters, e.g. for Java Stack Traces and JSON input.  Syslog Server (UDP) listener - logagent-js can also act as a syslog server and receive Syslog messages via UDP. The parser is applied to the message field.   Heroku Log Drain  makes it easy to ship Heroku logs to Elasticsearch or  Logsene  Cloud Foundry Log Drain", 
            "title": "Inputs"
        }, 
        {
            "location": "/#processing", 
            "text": "logagent-js applies patterns defined in patterns.yml to all logs and creates structured logs from plain-text log lines  GeoIP lookups for IP address fields, including automatic download and update of the GeoIP lite database from Maxmind", 
            "title": "Processing"
        }, 
        {
            "location": "/#reliable-log-shipping-with-disk-buffer", 
            "text": "Logagent doesn't lose data.  It stores parsed logs to a disk buffer if the network connection to the Elasticsearch API fails.  Logagent retries shipping logs later, when the network or Elasticsearch is available again.", 
            "title": "Reliable log shipping with disk buffer"
        }, 
        {
            "location": "/#outputs", 
            "text": "bulk inserts to  Logsene  / Elasticsearch API  JSON, line delimited JSON and YML to standard output", 
            "title": "Outputs"
        }, 
        {
            "location": "/#deployment-options", 
            "text": "Deployable as a system service: systemd, upstart (Linux), or launchd (Mac OS X)  Docker Container to receive logs via syslog  Deployement to Heroku as Heroku Log drain  Deployement to Cloud Foundry as Cloud Foundry Log drain (thus usable with Pivotal, Bluemix, etc.)", 
            "title": "Deployment options"
        }, 
        {
            "location": "/#api", 
            "text": "Node.js module to integrate parsers into Node.js programs  logagent-js is a part of  SPM for Docker  to parse Container Logs", 
            "title": "API"
        }, 
        {
            "location": "/#related-packages", 
            "text": "Sematext Agent for Docker  - collects metrics, events and logs from Docker API and CoreOS. Logagent-js is a component of sematext-agent-docker. More Information:  Innovative Docker Log Management  Logsene-CLI  - Enables searching Logsene log entries from the command-line.   SPM Agent for Node.js  - collects performance metrics for Node and io.js applications  Custom Metrics  - Custom Metrics for SPM   Winston-Logsene  - Logging for Node.js - Winston transport layer for Logsene", 
            "title": "Related packages"
        }, 
        {
            "location": "/#support", 
            "text": "Twitter:  @sematext  Blog:  sematext.com/blog  Homepage:  sematext.com", 
            "title": "Support"
        }, 
        {
            "location": "/installation/", 
            "text": "Install Node.js\n\n\nOfficial Node.js \ndownloads and instructions\n.\nE.g. for Debian/Ubuntu:\n\n\ncurl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\n\n\n\nInstall Logagent\n\n\nnpm i -g logagent-js\n# Test logs reading parsed with timestamps - output on console in YAML format (-y)\nlogagent -y /var/log/*.log\n\n\n\n\nLinux or Mac OS X service for Logsene\n\n\n\n\nGet a free account at \nsematext.com/spm\n\n\ncreate a Logsene App\n to obtain an App Token for \nLogsene\n \n\n\nInstall logagent as system service\nLogagent detects the init system and installs systemd or upstart service scripts. \nOn Mac OS X it creates a launchd service. Simply run:\n\n\n\n\nnpm i logagent-js -g # install logagent package globally\nsudo logagent-setup LOGSENE_TOKEN\n\n\n\n\nThe setup script generates a configuraton file in \n/etc/sematext/logagent.conf\n.\nThis file includes the CLI parameters for logagent running as service.\nThe default settings ship all logs from \n/var/log/**/*.log\n to Logsene. \n\n\nLocation of service scripts:\n- upstart: /etc/init/logagent.conf\n- systemd: /etc/systemd/system/logagent.service\n- launchd: /Library/LaunchDaemons/com.sematext.logagent.plist\n\n\nStart/stop service: \n- upstart: \nservice logagent stop/start\n\n- systemd: \nsystemctl stop/start logagent\n\n- lauchnchd: \nlaunchctl start/stop com.sematext.logagent\n\n\nRunning Logagent in a Docker Container as Syslog Listener\n\n\nYou can build a Docker image with logagent running in it and activing as a Syslog UDP listener.  Then you can run this as a container.  Once you have this \"containerized logagent\" you can start all yoour other containers with Syslog driver and point it to the \"containerized logagent's\" UDP port (514).  Here are the steps:\n\n\nBuild the docker image, and then run logagent inside it with the given LOGSENE_TOKEN\n\n\ngit clone https://github.com/sematext/logagent-js.git\ncd logagent-js\ndocker build -t logagent . \ndocker run -p 514:514/udp -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN -d --name logagent --restart=always logagent\n\n\n\n\nRun your other containers with Syslog driver\n\n\nexport $DOCKER_HOSTNAME=192.168.99.100\ndocker run --log-driver=syslog --log-opt syslog-address=udp://$DOCKER_HOSTNAME:514 --log-opt tag=\n{{.ImageName}}#{{.Name}}#{{.ID}}\n -p 9003:80 -d nginx\ncurl $DOCKER_HOSTNAME:9003\n\n\n\n\nContainer Options\n\n- Pass a custom pattern file\n\n\n-v $PWD/patterns.yml:/patterns.yml -e PATTERN_FILE=/patterns.yml\n\n\n\n\n\n\nSet any CLI option\ne.g. print logs in YML format to console (default is \"-s\" - silent)\n\n\n\n\n-e LOGAGENT_OPTIONS=\n-y\n\n\n\n\n\nTo view realtime logs in the Web Browser with rtail, simply add the options for rtail and open the http port for rtail-server UI. Please note: \nrtail UI might be slow for high log volumes\n\n\nexport LOGAGENT_OPTIONS=\n-s --rtail-host $HOSTNAME --rtail-web-port 80 --rtail-port 9999\n\ndocker run -p 8080:80 -p 514:514/udp -e LOGAGENT_OPTIONS -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN -d --name logagent --restart=always logagent\n\n\n\n\n\n\nSet Node.js Memory limits\n\n\n\n\n-e NODE_OPTIONS=\n--max-old-space-size=200\n\n\n\n\n\nPlease note \nSematext Agent Docker\n might be of interest if you like to collect logs, events and metrics from Docker. \n\n\nRun Logagent as Heroku Log Drain\n\n\nYou can forward your \nHeroku\n logs to Logsene using Heroku \nLog Drain\n like this:\n\n\nheroku drain:add --app HerokuAppName URL\n\n\n\n\nHere are the steps:\n\n\nTo ship your Heroku logs to Logsene or Elasticsearch deploy Logagent on Heroku. It will act as an HTTPS log drain. \n\n\n\n\nGet a free account \napps.sematext.com\n\n\nCreate a \nLogsene\n App to obtain the Logsene Token\n\n\nDeploy logagent-js to Heroku using the Deploy to Heroku button\n\n\n\n\n \n... or use the following commands:\n\n\ngit clone https://github.com/sematext/logagent-js.git\n  cd logagent-js\n  heroku login \n  heroku create\n  git push heroku master\n\n4. Add the log drain using the URL format like https://loggerAppName.herokuapps.com/LOGSENE_TOKEN.\n  Use the following command to grab the dynamically assigned name from \"heroku create\" command.\n\n\nexport LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN\n  heroku drains:add --app YOUR_HEROKU_MAIN_APPLICATION `heroku info -s | grep web-url | cut -d= -f2`$LOGSENE_TOKEN\n\nNow you can see your logs in Logsene, define Alert-Queries or use Kibana for Dashboards. \n\n\n\n\nScale logagent-js service on Heroku\n\n\n\n\nIn case of high log volume, scale logagent-js on demand using \n\n\nheroku scale web=3\n\n\n\n\nSee also:\n- \nHow to Ship Heroku Logs to Logsene / Managed ELK Stack", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#install-nodejs", 
            "text": "Official Node.js  downloads and instructions .\nE.g. for Debian/Ubuntu:  curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\nsudo apt-get install -y nodejs", 
            "title": "Install Node.js"
        }, 
        {
            "location": "/installation/#install-logagent", 
            "text": "npm i -g logagent-js\n# Test logs reading parsed with timestamps - output on console in YAML format (-y)\nlogagent -y /var/log/*.log", 
            "title": "Install Logagent"
        }, 
        {
            "location": "/installation/#linux-or-mac-os-x-service-for-logsene", 
            "text": "Get a free account at  sematext.com/spm  create a Logsene App  to obtain an App Token for  Logsene    Install logagent as system service\nLogagent detects the init system and installs systemd or upstart service scripts. \nOn Mac OS X it creates a launchd service. Simply run:   npm i logagent-js -g # install logagent package globally\nsudo logagent-setup LOGSENE_TOKEN  The setup script generates a configuraton file in  /etc/sematext/logagent.conf .\nThis file includes the CLI parameters for logagent running as service.\nThe default settings ship all logs from  /var/log/**/*.log  to Logsene.   Location of service scripts:\n- upstart: /etc/init/logagent.conf\n- systemd: /etc/systemd/system/logagent.service\n- launchd: /Library/LaunchDaemons/com.sematext.logagent.plist  Start/stop service: \n- upstart:  service logagent stop/start \n- systemd:  systemctl stop/start logagent \n- lauchnchd:  launchctl start/stop com.sematext.logagent", 
            "title": "Linux or Mac OS X service for Logsene"
        }, 
        {
            "location": "/installation/#running-logagent-in-a-docker-container-as-syslog-listener", 
            "text": "You can build a Docker image with logagent running in it and activing as a Syslog UDP listener.  Then you can run this as a container.  Once you have this \"containerized logagent\" you can start all yoour other containers with Syslog driver and point it to the \"containerized logagent's\" UDP port (514).  Here are the steps:  Build the docker image, and then run logagent inside it with the given LOGSENE_TOKEN  git clone https://github.com/sematext/logagent-js.git\ncd logagent-js\ndocker build -t logagent . \ndocker run -p 514:514/udp -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN -d --name logagent --restart=always logagent  Run your other containers with Syslog driver  export $DOCKER_HOSTNAME=192.168.99.100\ndocker run --log-driver=syslog --log-opt syslog-address=udp://$DOCKER_HOSTNAME:514 --log-opt tag= {{.ImageName}}#{{.Name}}#{{.ID}}  -p 9003:80 -d nginx\ncurl $DOCKER_HOSTNAME:9003  Container Options \n- Pass a custom pattern file  -v $PWD/patterns.yml:/patterns.yml -e PATTERN_FILE=/patterns.yml   Set any CLI option\ne.g. print logs in YML format to console (default is \"-s\" - silent)   -e LOGAGENT_OPTIONS= -y   To view realtime logs in the Web Browser with rtail, simply add the options for rtail and open the http port for rtail-server UI. Please note:  rtail UI might be slow for high log volumes  export LOGAGENT_OPTIONS= -s --rtail-host $HOSTNAME --rtail-web-port 80 --rtail-port 9999 \ndocker run -p 8080:80 -p 514:514/udp -e LOGAGENT_OPTIONS -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN -d --name logagent --restart=always logagent   Set Node.js Memory limits   -e NODE_OPTIONS= --max-old-space-size=200   Please note  Sematext Agent Docker  might be of interest if you like to collect logs, events and metrics from Docker.", 
            "title": "Running Logagent in a Docker Container as Syslog Listener"
        }, 
        {
            "location": "/installation/#run-logagent-as-heroku-log-drain", 
            "text": "You can forward your  Heroku  logs to Logsene using Heroku  Log Drain  like this:  heroku drain:add --app HerokuAppName URL  Here are the steps:  To ship your Heroku logs to Logsene or Elasticsearch deploy Logagent on Heroku. It will act as an HTTPS log drain.    Get a free account  apps.sematext.com  Create a  Logsene  App to obtain the Logsene Token  Deploy logagent-js to Heroku using the Deploy to Heroku button    \n... or use the following commands:  git clone https://github.com/sematext/logagent-js.git\n  cd logagent-js\n  heroku login \n  heroku create\n  git push heroku master \n4. Add the log drain using the URL format like https://loggerAppName.herokuapps.com/LOGSENE_TOKEN.\n  Use the following command to grab the dynamically assigned name from \"heroku create\" command.  export LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN\n  heroku drains:add --app YOUR_HEROKU_MAIN_APPLICATION `heroku info -s | grep web-url | cut -d= -f2`$LOGSENE_TOKEN \nNow you can see your logs in Logsene, define Alert-Queries or use Kibana for Dashboards.    Scale logagent-js service on Heroku   In case of high log volume, scale logagent-js on demand using   heroku scale web=3  See also:\n-  How to Ship Heroku Logs to Logsene / Managed ELK Stack", 
            "title": "Run Logagent as Heroku Log Drain"
        }, 
        {
            "location": "/cli-parameters/", 
            "text": "Command Line Parameters for logagent\n\n\n\n\n\n\n\n\nParamater\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-f\n patterns.yml\n\n\nfile with pattern definitions\n\n\n\n\n\n\n-y\n\n\nprints parsed messages in YAML format to stdout\n\n\n\n\n\n\n-p\n\n\npretty json output\n\n\n\n\n\n\n-s\n\n\nsilent, print no logs, only throughput and memory usage on exit\n\n\n\n\n\n\n-t\n token\n\n\nLogsene\n App Token to insert parsed records into Logsene.\n\n\n\n\n\n\n-g\n glob-pattern\n\n\nuse a \nglob\n pattern to watch log files e.g. -g \"{/var/log/\n.log,/Users/stefan/\n/*.log}\"\n\n\n\n\n\n\n--logsene-tmp-dir\n  path\n\n\ndirectory to store buffered logs during network outage\n\n\n\n\n\n\n-u\n UDP_PORT\n\n\nstarts a syslogd UDP listener on the given port to act as syslogd\n\n\n\n\n\n\n-n\n name\n\n\nname for the source only when stdin is used, important to make multi-line patterns working on stdin because the status is tracked by the source name.\n\n\n\n\n\n\n--heroku\n PORT\n\n\nlistens for Heroku logs (http drain / framed syslog over http)\n\n\n\n\n\n\n--cfhttp\n PORT\n\n\nlistens for Cloud Foundry logs (syslog over http)\n\n\n\n\n\n\n--rtail-port\n\n\nforwards logs via UDP to \nrtail\n server\n\n\n\n\n\n\n--rtail-host\n hostname\n\n\nrtail\n server (UI for realtime logs), default: localhost\n\n\n\n\n\n\nlist of files\n, e.g. /var/log/*.log\n\n\nwatched by \ntail-forever\n starting at end of file\n\n\n\n\n\n\n\n\nThe default output is line delimited JSON.\n\n\nEnvironment variables\n\n\n\n\n\n\n\n\nVariable\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nLOGSENE_TMP_DIR\n\n\nDirectory to store failed bulk requests, for later re-transmission.\n\n\n\n\n\n\nLOGSENE_LOG_INTERVAL\n\n\nTime to batch logs before a bulk request is done. Default 10000 ms (10 seconds)\n\n\n\n\n\n\nLOGSENE_BULK_SIZE\n\n\nMaximum size of a bulk request. Default 1000.\n\n\n\n\n\n\nLOGSENE_URL\n\n\nURL for the Logsene receiver. For a local Elasticsearch server or for On-Premise version of Logsene. Defaults to Sematext Logsene SaaS receiver https://logsene-receiver.sematext.com/_bulk. Example for Elasticsearch: \nLOGSENE_URL=http://localhost:9200/_bulk\n\n\n\n\n\n\nHTTPS_PROXY\n\n\nProxy URL for HTTPS endpoints, like Logsene receiver. \nexport HTTPS_PROXY=http://my-proxy.example\n\n\n\n\n\n\nHTTP_PROXY\n\n\nProxy URL for HTTP endpoints (e.g. On-Premises or local Elasticsearch). \nexport HTTP_PROXY=http://my-proxy.example\n\n\n\n\n\n\n\n\nCommand Line Examples\n\n\n# Be Evil: parse all logs \n# stream logs to Logsene 1-Click ELK stack \nlogagent -t LOGSENE_TOKEN /var/log/*.log \n\n# Act as syslog server on UDP and forward messages to Logsene\nlogagent -u 514 -t LOGSENE_TOKEN  \n\n# Act as syslog server on UDP and write YAML formatted messages to console\nlogagent -u 514 -y  \n\n\n\n\nUse a \nglob\n pattern to build the file list \n\n\nlogagent -t LOGSENE_TOKEN -g \n{/var/log/*.log,/opt/myapp/*.log}\n \n\n\n\n\nWatch selective log output on console by passing logs via stdin and format in YAML\n\n\ntail -f /var/log/access.log | logagent -y \ntail -f /var/log/system.log | logagent -f my_own_patterns.yml  -y \n\n\n\n\nShip logs to rtail and Logsene to view logs in real-time in rtail and store logs in Logsene\n\n\n# rtail don't need to be installed, logagent uses the rtail protocol\nlogagent -t $LOGSENE_TOKEN --rtail-host myrtailserver --rtail-port 9999 /var/log/*.log\n\n\n\n\nLogagent can start the rtail web-server (in-process, saving memory), open browser with http://localhost:8080\n\n\n# logagent has no dependency to rtail, to keep the package small\nsudo npm i rtail -g\nlogagent -s -t $LOGSENE_TOKEN --rtail-web-port 8080 --rtail-port 9999 /var/log/*.log\n\n\n\n\nAnd of course you can combine rtail and Logagent in the traditional way, simply connect both via unix pipes. An example with rtail and Logsene storage and charts:", 
            "title": "Command Line Options"
        }, 
        {
            "location": "/cli-parameters/#command-line-parameters-for-logagent", 
            "text": "Paramater  Description      -f  patterns.yml  file with pattern definitions    -y  prints parsed messages in YAML format to stdout    -p  pretty json output    -s  silent, print no logs, only throughput and memory usage on exit    -t  token  Logsene  App Token to insert parsed records into Logsene.    -g  glob-pattern  use a  glob  pattern to watch log files e.g. -g \"{/var/log/ .log,/Users/stefan/ /*.log}\"    --logsene-tmp-dir   path  directory to store buffered logs during network outage    -u  UDP_PORT  starts a syslogd UDP listener on the given port to act as syslogd    -n  name  name for the source only when stdin is used, important to make multi-line patterns working on stdin because the status is tracked by the source name.    --heroku  PORT  listens for Heroku logs (http drain / framed syslog over http)    --cfhttp  PORT  listens for Cloud Foundry logs (syslog over http)    --rtail-port  forwards logs via UDP to  rtail  server    --rtail-host  hostname  rtail  server (UI for realtime logs), default: localhost    list of files , e.g. /var/log/*.log  watched by  tail-forever  starting at end of file     The default output is line delimited JSON.", 
            "title": "Command Line Parameters for logagent"
        }, 
        {
            "location": "/cli-parameters/#environment-variables", 
            "text": "Variable  Description      LOGSENE_TMP_DIR  Directory to store failed bulk requests, for later re-transmission.    LOGSENE_LOG_INTERVAL  Time to batch logs before a bulk request is done. Default 10000 ms (10 seconds)    LOGSENE_BULK_SIZE  Maximum size of a bulk request. Default 1000.    LOGSENE_URL  URL for the Logsene receiver. For a local Elasticsearch server or for On-Premise version of Logsene. Defaults to Sematext Logsene SaaS receiver https://logsene-receiver.sematext.com/_bulk. Example for Elasticsearch:  LOGSENE_URL=http://localhost:9200/_bulk    HTTPS_PROXY  Proxy URL for HTTPS endpoints, like Logsene receiver.  export HTTPS_PROXY=http://my-proxy.example    HTTP_PROXY  Proxy URL for HTTP endpoints (e.g. On-Premises or local Elasticsearch).  export HTTP_PROXY=http://my-proxy.example", 
            "title": "Environment variables"
        }, 
        {
            "location": "/cli-parameters/#command-line-examples", 
            "text": "# Be Evil: parse all logs \n# stream logs to Logsene 1-Click ELK stack \nlogagent -t LOGSENE_TOKEN /var/log/*.log \n\n# Act as syslog server on UDP and forward messages to Logsene\nlogagent -u 514 -t LOGSENE_TOKEN  \n\n# Act as syslog server on UDP and write YAML formatted messages to console\nlogagent -u 514 -y    Use a  glob  pattern to build the file list   logagent -t LOGSENE_TOKEN -g  {/var/log/*.log,/opt/myapp/*.log}    Watch selective log output on console by passing logs via stdin and format in YAML  tail -f /var/log/access.log | logagent -y \ntail -f /var/log/system.log | logagent -f my_own_patterns.yml  -y   Ship logs to rtail and Logsene to view logs in real-time in rtail and store logs in Logsene  # rtail don't need to be installed, logagent uses the rtail protocol\nlogagent -t $LOGSENE_TOKEN --rtail-host myrtailserver --rtail-port 9999 /var/log/*.log  Logagent can start the rtail web-server (in-process, saving memory), open browser with http://localhost:8080  # logagent has no dependency to rtail, to keep the package small\nsudo npm i rtail -g\nlogagent -s -t $LOGSENE_TOKEN --rtail-web-port 8080 --rtail-port 9999 /var/log/*.log  And of course you can combine rtail and Logagent in the traditional way, simply connect both via unix pipes. An example with rtail and Logsene storage and charts:", 
            "title": "Command Line Examples"
        }, 
        {
            "location": "/parser/", 
            "text": "How does the parser work?\n\n\nThe parser detects log formats based on a pattern library (yaml file) and converts it to a JSON Object:\n\n\n\n\nfind matching regex in pattern library\n\n\ntag it with the recognized type\n\n\nextract fields using regex\n\n\nif 'autohash' is enabled, sensitive data is replaced with its sha1 hash code\n\n\nparse dates and detect date format\n  (use 'ts' field for date and time combined) \n\n\ncreate ISO timestamp in '@timestamp' field\n\n\ntransform function to manipulate parsed objects\n\n\nunmatched lines end up with timestamp and original line in the message field\n\n\nJSON lines are parsed, and scanned for @timestamp and time fields (logstash and bunyan format)\n\n\ndefault patterns for many applications (see below)\n\n\nHeroku logs\n\n\n\n\nThe default pattern definition file comes with patterns for:\n\n\n\n\nMongoDB\n\n\nMySQL\n\n\nNginx\n\n\nRedis\n\n\nElasticsearch\n\n\nWebserver (nginx, apache httpd)\n\n\nZookeeper\n\n\nCassandra\n\n\nKafka\n\n\nHBase HDFS Data Node\n\n\nHBase Region Server\n\n\nHadoop YARN Node Manager\n\n\nApache Solr\n\n\nvarious Linux/Mac OS X system log files\n\n\n\n\nThe file format is based on \nJS-YAML\n, in short:\n\n\n- - indicates an  array\n- !js/regexp - indicates a JS regular expression\n- !!js/function \n - indicates a JS function \n\n\n\n\nProperties:\n\n\n\n\npatterns: list of patterns, each pattern starts with \"-\"\n\n\nmatch: group of patterns for a specific log source\n\n\nregex: JS regular expression \n\n\nfields: field list of extracted match groups from the regex\n\n\ntype: type used in Logsene (Elasticsearch Mapping)\n\n\ndateFormat: format of the special fields 'ts', if the date format matches, a new field @timestamp is generated\n\n\ntransform: JS function to manipulate the result of regex and date parsing\n\n\n\n\nExample\n\n\n# Sensitive data can be replaced with a hashcode (sha1)\n# it applies to fields matching the field names by a regular expression\n# Note: this function is not optimized (yet) and might take 10-15% of performance\nautohash: !!js/regexp /user|password|email|credit_card_number|payment_info/i\n\n# set this to false when autohash fields\n# the original line might include sensitive data!\noriginalLine: false\n\n# activate GeoIP lookup\ngeoIP: true\n\n# logagent updates geoip db files automatically\n# pls. note write access to this directory is required\nmaxmindDbDir: /tmp/\n\npatterns: \n  - # APACHE  Web Logs\n  sourceName: httpd\n  match: \n    # Common Log Format\n    - regex:        !!js/regexp /([0-9a-f.:]+)\\s+(-|.+?)\\s+(-|.+?)\\s+\\[([0-9]{2}\\/[a-z]{3}\\/[0-9]{4}\\:[0-9]{2}:[0-9]{2}:[0-9]{2}[^\\]]*)\\] \\\n(\\S+?)\\s(\\S*?)\\s{0,1}(\\S+?)\\\n ([0-9|\\-]+) ([0-9|\\-]+)/i\n      type: apache_access_common\n      fields:       [client_ip,remote_id,user,ts,method,path,http_version,status_code,size]\n      dateFormat: DD/MMM/YYYY:HH:mm:ss ZZ\n      # lookup geoip info for the field client_ip\n      geoIP: client_ip\n      transform: !!js/function \n\n        function (p) {\n          p.message = p.method + ' ' + p.path\n        }\n\n\n\n\nThe default patterns are \nhere\n - contributions are welcome!", 
            "title": "Log Parser and pattern definitions"
        }, 
        {
            "location": "/parser/#how-does-the-parser-work", 
            "text": "The parser detects log formats based on a pattern library (yaml file) and converts it to a JSON Object:   find matching regex in pattern library  tag it with the recognized type  extract fields using regex  if 'autohash' is enabled, sensitive data is replaced with its sha1 hash code  parse dates and detect date format\n  (use 'ts' field for date and time combined)   create ISO timestamp in '@timestamp' field  transform function to manipulate parsed objects  unmatched lines end up with timestamp and original line in the message field  JSON lines are parsed, and scanned for @timestamp and time fields (logstash and bunyan format)  default patterns for many applications (see below)  Heroku logs   The default pattern definition file comes with patterns for:   MongoDB  MySQL  Nginx  Redis  Elasticsearch  Webserver (nginx, apache httpd)  Zookeeper  Cassandra  Kafka  HBase HDFS Data Node  HBase Region Server  Hadoop YARN Node Manager  Apache Solr  various Linux/Mac OS X system log files   The file format is based on  JS-YAML , in short:  - - indicates an  array\n- !js/regexp - indicates a JS regular expression\n- !!js/function   - indicates a JS function   Properties:   patterns: list of patterns, each pattern starts with \"-\"  match: group of patterns for a specific log source  regex: JS regular expression   fields: field list of extracted match groups from the regex  type: type used in Logsene (Elasticsearch Mapping)  dateFormat: format of the special fields 'ts', if the date format matches, a new field @timestamp is generated  transform: JS function to manipulate the result of regex and date parsing", 
            "title": "How does the parser work?"
        }, 
        {
            "location": "/parser/#example", 
            "text": "# Sensitive data can be replaced with a hashcode (sha1)\n# it applies to fields matching the field names by a regular expression\n# Note: this function is not optimized (yet) and might take 10-15% of performance\nautohash: !!js/regexp /user|password|email|credit_card_number|payment_info/i\n\n# set this to false when autohash fields\n# the original line might include sensitive data!\noriginalLine: false\n\n# activate GeoIP lookup\ngeoIP: true\n\n# logagent updates geoip db files automatically\n# pls. note write access to this directory is required\nmaxmindDbDir: /tmp/\n\npatterns: \n  - # APACHE  Web Logs\n  sourceName: httpd\n  match: \n    # Common Log Format\n    - regex:        !!js/regexp /([0-9a-f.:]+)\\s+(-|.+?)\\s+(-|.+?)\\s+\\[([0-9]{2}\\/[a-z]{3}\\/[0-9]{4}\\:[0-9]{2}:[0-9]{2}:[0-9]{2}[^\\]]*)\\] \\ (\\S+?)\\s(\\S*?)\\s{0,1}(\\S+?)\\  ([0-9|\\-]+) ([0-9|\\-]+)/i\n      type: apache_access_common\n      fields:       [client_ip,remote_id,user,ts,method,path,http_version,status_code,size]\n      dateFormat: DD/MMM/YYYY:HH:mm:ss ZZ\n      # lookup geoip info for the field client_ip\n      geoIP: client_ip\n      transform: !!js/function  \n        function (p) {\n          p.message = p.method + ' ' + p.path\n        }  The default patterns are  here  - contributions are welcome!", 
            "title": "Example"
        }, 
        {
            "location": "/nodejs-api/", 
            "text": "Install logagent as local module and save the dependency to your package.json\n\n\nnpm i logagent-js --save\n\n\n\n\nUse the Logparser module in your source code\n\n\nvar Logparser = require('logagent-js')\nvar lp = new Logparser('./patterns.yml')\nlp.parseLine('log message', 'source name', function (err, data) {\n    if(err) {\n      console.log('line did not match any pattern')\n    }\n    console.log(JSON.stringify(data))\n})\n\n\n\n\nTo test patterns or convert logs from text to JSON use the command line tool 'logagent'. It reads from stdin and outputs line delimited JSON (or pretty JSON or YAML) to the console. In addition, it can forward the parsed objects directly to \nLogsene\n or Elasticsearch.\n\n\nTest your patterns:\n\n\ncat myapp.log | bin/logagent -y -n myapp -f mypatterns.yml", 
            "title": "Node.js API"
        }
    ]
}