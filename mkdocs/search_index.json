{
    "docs": [
        {
            "location": "/", 
            "text": "- \nread more\n\n\nlogagent-js\n\n\nSmart Log Parser and Log Shipper written in Node. \n\n\nFeatures\n\n\nThis project contains a library and patterns for log parsing and cli tools and installers to use logagent-js as log shipper with following features: \n\n\nParser\n\n\n\n\nlog format detection and intelligent pattern matching \n\n\npattern library included \n\n\nrecognition of Date and Number fields\n\n\neasy to extend with custom patterns and JS transform functions\n\n\nreplace sensitive data with SHA-1 hash codes\n\n\nGeoIP lookup with automatic GeoIP db updates (maxmind geopip-lite files)\n\n\n\n\nCommand Line Tool\n\n\n\n\nlog format converter (e.g. text to JSON, line delimited JSON or YAML) \n\n\n\n\nLog shipper for \nLogsene\n\n\n\n\n\n\nincluding cli, launchd (Mac OS X), upstart and systemd (Linux) service installer\n\n\n\n\ndisk buffer for failed inserts during network outage\n\n\n\n\nInputs\n\n\n\n\nStandart input (stdin) taking the output stream from any Linux cli tool\n\n\npatterns are applied to each incomming text lines, including support for multi-line patters, e.g. for Java Stack Traces and JSON parser. \n\n\nSyslog Server (UDP) - reception of Syslog messages via UDP. The parser is applied to the message field. \n\n\nHeroku Log Drain\n\n\nCloudFoundry Log Drain\n\n\n\n\nProcessing\n\n\n\n\nlogagent-js applies the patterns defined in ```patterns.yml' to all logs to create structured output from plain text lines. Patterns are defined for input sources with regular expressions. The parsed logs can be post-processed with node.js transform function e.g. to enrich data or perform complex parser operations. \n\n\nGeoIP lookups for IP adress fields, including download and update of the GeoIP lite database from Maxmind\n\n\n\n\nSecurity\n\n\n\n\nMasking sensitive data - Logagent can relace field content with SHA-1 hash codes to mask sensitive data. The advantage of hash codes is that data is still searchable when you hash the original value before you start a search.  In addtion it is possible to exclude the original log line from shipping to avoid that sensitive data gets shipped in the field \"originalLogLine\".\n\n\nShipping logs to Logsene is done via https by default \n\n\nSupport of proxy servers if the logging server is behind a firewall\n\n\n\n\nReliable log shipping with disk buffer\n\n\nLogagent stores parsed logs to disk in case the network connection to the Elasticsearch API fails. Logagent retries to ship the logs later, when the network or Elasticsearch server is available again.  \n\n\nOutputs\n\n\n\n\nbulk inserts to \nLogsene\n / Elasticsearch API\n\n\nJSON, line delimited JSON and YML to stadard output  \n\n\n\n\nDeployment options\n\n\n\n\nDeployable as system service: systemd, upstart (Linux) launchd (Mac OS X)setups \n\n\nDocker Container to receive logs via syslog\n\n\nDeployement to Heroku as Heroku Log drain\n\n\n\n\nAPI\n\n\n\n\nNode.js module to integrate parsers into Node.js programs\n\n\nlogagent-js is part of \nSPM for Docker\n to parse Container Logs\n\n\n\n\nRelated packages\n\n\n\n\nSematext Agent for Docker\n - collects metrics, events and logs from Docker API and CoreOS. Logagent-js is a component of sematext-agent-docker. More Information: \nInnovative Docker Log Management\n\n\nLogsene-CLI\n - Enables searching Logsene log entries from the command-line. \n\n\nSPM Agent for Node.js\n - collects performance metrics for Node and io.js applications\n\n\nCustom Metrics\n - Custom Metrics for SPM \n\n\nWinston-Logsene\n - Logging for Node.js - Winston transport layer for Logsene\n\n\n\n\nSupport\n\n\n\n\nTwitter: \n@sematext\n\n\nBlog: \nblog.sematext.com\n\n\nHomepage: \nwww.sematext.com", 
            "title": "Features and Overview"
        }, 
        {
            "location": "/#logagent-js", 
            "text": "Smart Log Parser and Log Shipper written in Node.", 
            "title": "logagent-js"
        }, 
        {
            "location": "/#features", 
            "text": "This project contains a library and patterns for log parsing and cli tools and installers to use logagent-js as log shipper with following features:", 
            "title": "Features"
        }, 
        {
            "location": "/#parser", 
            "text": "log format detection and intelligent pattern matching   pattern library included   recognition of Date and Number fields  easy to extend with custom patterns and JS transform functions  replace sensitive data with SHA-1 hash codes  GeoIP lookup with automatic GeoIP db updates (maxmind geopip-lite files)", 
            "title": "Parser"
        }, 
        {
            "location": "/#command-line-tool", 
            "text": "log format converter (e.g. text to JSON, line delimited JSON or YAML)    Log shipper for  Logsene    including cli, launchd (Mac OS X), upstart and systemd (Linux) service installer   disk buffer for failed inserts during network outage", 
            "title": "Command Line Tool"
        }, 
        {
            "location": "/#inputs", 
            "text": "Standart input (stdin) taking the output stream from any Linux cli tool  patterns are applied to each incomming text lines, including support for multi-line patters, e.g. for Java Stack Traces and JSON parser.   Syslog Server (UDP) - reception of Syslog messages via UDP. The parser is applied to the message field.   Heroku Log Drain  CloudFoundry Log Drain", 
            "title": "Inputs"
        }, 
        {
            "location": "/#processing", 
            "text": "logagent-js applies the patterns defined in ```patterns.yml' to all logs to create structured output from plain text lines. Patterns are defined for input sources with regular expressions. The parsed logs can be post-processed with node.js transform function e.g. to enrich data or perform complex parser operations.   GeoIP lookups for IP adress fields, including download and update of the GeoIP lite database from Maxmind", 
            "title": "Processing"
        }, 
        {
            "location": "/#security", 
            "text": "Masking sensitive data - Logagent can relace field content with SHA-1 hash codes to mask sensitive data. The advantage of hash codes is that data is still searchable when you hash the original value before you start a search.  In addtion it is possible to exclude the original log line from shipping to avoid that sensitive data gets shipped in the field \"originalLogLine\".  Shipping logs to Logsene is done via https by default   Support of proxy servers if the logging server is behind a firewall", 
            "title": "Security"
        }, 
        {
            "location": "/#reliable-log-shipping-with-disk-buffer", 
            "text": "Logagent stores parsed logs to disk in case the network connection to the Elasticsearch API fails. Logagent retries to ship the logs later, when the network or Elasticsearch server is available again.", 
            "title": "Reliable log shipping with disk buffer"
        }, 
        {
            "location": "/#outputs", 
            "text": "bulk inserts to  Logsene  / Elasticsearch API  JSON, line delimited JSON and YML to stadard output", 
            "title": "Outputs"
        }, 
        {
            "location": "/#deployment-options", 
            "text": "Deployable as system service: systemd, upstart (Linux) launchd (Mac OS X)setups   Docker Container to receive logs via syslog  Deployement to Heroku as Heroku Log drain", 
            "title": "Deployment options"
        }, 
        {
            "location": "/#api", 
            "text": "Node.js module to integrate parsers into Node.js programs  logagent-js is part of  SPM for Docker  to parse Container Logs", 
            "title": "API"
        }, 
        {
            "location": "/#related-packages", 
            "text": "Sematext Agent for Docker  - collects metrics, events and logs from Docker API and CoreOS. Logagent-js is a component of sematext-agent-docker. More Information:  Innovative Docker Log Management  Logsene-CLI  - Enables searching Logsene log entries from the command-line.   SPM Agent for Node.js  - collects performance metrics for Node and io.js applications  Custom Metrics  - Custom Metrics for SPM   Winston-Logsene  - Logging for Node.js - Winston transport layer for Logsene", 
            "title": "Related packages"
        }, 
        {
            "location": "/#support", 
            "text": "Twitter:  @sematext  Blog:  blog.sematext.com  Homepage:  www.sematext.com", 
            "title": "Support"
        }, 
        {
            "location": "/installation/", 
            "text": "Preparation: Install Node.js\n\n\nOfficial Node.js \ndownloads and instructions\n.\nE.g. for Debian/Ubuntu:\n\n\ncurl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\n\n\n\nLogagnet command line tool with npm\n\n\nnpm i -g logagent-js\n# Test to ship your logs to Logsene, parsed with timestamps - output on console in YAML format (-y)\nlogagent -y /var/log/*.log\n\n\n\n\nLinux or Mac OS X service for Logsene\n\n\n\n\nGet a free account at \nsematext.com/spm\n  \n\n\ncreate a Logsene App\n to obtain an App Token for \nLogsene\n \n\n\nInstall logagnet as system service\nLogagent detects the init system and installs systemd or upstart service scripts. \nOn Mac OS X it creates a launchd service. Simply run:\n\n\n\n\nnpm i logagent-js -g # install logagent package globally\nsudo logagent-setup LOGSENE_TOKEN\n\n\n\n\nThe setup script generates a configuraton file in \n/etc/sematext/logagent.conf\n.\nThis file includes the CLI parameters for logagent running as service.\nThe default settings ship all logs from \n`/var/log/**/*.log\n to Logsene. \n\n\nLocation of service scripts:\n- upstart: /etc/init/logagent.conf\n- systemd: /etc/systemd/system/logagent.service\n- launchd: /Library/LaunchDaemons/com.sematext.logagent.plist\n\n\nStart/stop service: \n- upstart: \nservice logagent stop/start\n\n- systemd: \nsystemctl stop/start logagent\n\n- lauchnchd: \nlaunchctl start/stop com.sematext.logagent\n\n\nDocker - receive logs via syslog\n\n\nBuild the image and start logagent with the LOGSENE_TOKEN\n\n\ngit clone https://github.com/sematext/logagent-js.git\ncd logagent-js\ndocker build -t logagent . \ndocker run -p 514:514/udp -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN  -d --name logagent --restart=always logagent\n\n\n\n\nRun your container with syslog driver\n\n\nexport $DOCKER_HOSTNAME=192.168.99.100\ndocker run --log-driver=syslog  --log-opt syslog-address=udp://$DOCKER_HOSTNAME:514 --log-opt tag=\n{{.ImageName}}#{{.Name}}#{{.ID}}\n -p 9003:80 -d nginx\ncurl $DOCKER_HOSTNAME:9003\n\n\n\n\nContainer Options\n\n- Pass a custom pattern file\n\n\n-v $PWD/patterns.yml:/patterns.yml -e PATTERN_FILE=/patterns.yml\n\n\n\n\n\n\nSet any CLI option\ne.g. print logs in YML format to console (default is \"-s\" - silent)\n\n\n\n\n-e LOGAGENT_OPTIONS=\n-y\n\n\n\n\n\nTo view realtime logs in the Web Browser with rtail, simply add the options for rtail and open the http port for rtail-server UI. Please note: \nrtail UI might be slow for high log volumes\n\n\nexport LOGAGENT_OPTIONS=\n-s --rtail-host $HOSTNAME --rtail-web-port 80 --rtail-port 9999\n\ndocker run -p 8080:80 -p 514:514/udp -e LOGAGENT_OPTIONS -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN  -d --name logagent --restart=always logagent\n\n\n\n\n\n\nSet Node.js Memory limits\n\n\n\n\n-e NODE_OPTIONS=\n--max-old-space-size=200\n\n\n\n\n\nPlease note \nSematext Agent Docker\n might be of interest if you like to collect logs, events and metrics from Docker. \n\n\nInstall logagent as Heroku log drain\n\n\nHeroku\n can forward logs to a \nLog Drain\n \n\n\nheroku drain:add --app HerokuAppName URL \n\n\n\n\nTo receive Heroku logs, logagent-js can be deployed to Heroku. It acts as HTTPS log drain. \n\n\n\n\nGet a free account \napps.sematext.com\n  \n\n\nCreate a \nLogsene\n App to obtain the Logsene Token\n\n\nDeploy logagent-js to Heroku \n\n\n\n\n or use the following commands:\n\n\ngit clone https://github.com/sematext/logagent-js.git\n  cd logagent-js\n  heroku login \n  heroku create\n  git push heroku master\n\n4. Add the the log drain.\n\n  The URL format is https://loggerAppName.herokuapps.com/LOGSENE_TOKEN\n  Use following command, using the dynamically given name from \"heroku create\".\n\n\nexport LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN\n  heroku drains:add --app YOUR_HEROKU_MAIN_APPLICATION  `heroku info -s | grep web-url | cut -d= -f2`$LOGSENE_TOKEN\n\nNow you can see your logs in Logsene, define Alert-Queries or use Kibana for Dashboards. \n\n\n\n\nScale logagent-js service on Heroku\n\n\n\n\nIn case of high log volume, scale logagent-js  on demand using \n\n\nheroku scale web=3", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#preparation-install-nodejs", 
            "text": "Official Node.js  downloads and instructions .\nE.g. for Debian/Ubuntu:  curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\nsudo apt-get install -y nodejs", 
            "title": "Preparation: Install Node.js"
        }, 
        {
            "location": "/installation/#logagnet-command-line-tool-with-npm", 
            "text": "npm i -g logagent-js\n# Test to ship your logs to Logsene, parsed with timestamps - output on console in YAML format (-y)\nlogagent -y /var/log/*.log", 
            "title": "Logagnet command line tool with npm"
        }, 
        {
            "location": "/installation/#linux-or-mac-os-x-service-for-logsene", 
            "text": "Get a free account at  sematext.com/spm     create a Logsene App  to obtain an App Token for  Logsene    Install logagnet as system service\nLogagent detects the init system and installs systemd or upstart service scripts. \nOn Mac OS X it creates a launchd service. Simply run:   npm i logagent-js -g # install logagent package globally\nsudo logagent-setup LOGSENE_TOKEN  The setup script generates a configuraton file in  /etc/sematext/logagent.conf .\nThis file includes the CLI parameters for logagent running as service.\nThe default settings ship all logs from  `/var/log/**/*.log  to Logsene.   Location of service scripts:\n- upstart: /etc/init/logagent.conf\n- systemd: /etc/systemd/system/logagent.service\n- launchd: /Library/LaunchDaemons/com.sematext.logagent.plist  Start/stop service: \n- upstart:  service logagent stop/start \n- systemd:  systemctl stop/start logagent \n- lauchnchd:  launchctl start/stop com.sematext.logagent", 
            "title": "Linux or Mac OS X service for Logsene"
        }, 
        {
            "location": "/installation/#docker-receive-logs-via-syslog", 
            "text": "Build the image and start logagent with the LOGSENE_TOKEN  git clone https://github.com/sematext/logagent-js.git\ncd logagent-js\ndocker build -t logagent . \ndocker run -p 514:514/udp -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN  -d --name logagent --restart=always logagent  Run your container with syslog driver  export $DOCKER_HOSTNAME=192.168.99.100\ndocker run --log-driver=syslog  --log-opt syslog-address=udp://$DOCKER_HOSTNAME:514 --log-opt tag= {{.ImageName}}#{{.Name}}#{{.ID}}  -p 9003:80 -d nginx\ncurl $DOCKER_HOSTNAME:9003  Container Options \n- Pass a custom pattern file  -v $PWD/patterns.yml:/patterns.yml -e PATTERN_FILE=/patterns.yml   Set any CLI option\ne.g. print logs in YML format to console (default is \"-s\" - silent)   -e LOGAGENT_OPTIONS= -y   To view realtime logs in the Web Browser with rtail, simply add the options for rtail and open the http port for rtail-server UI. Please note:  rtail UI might be slow for high log volumes  export LOGAGENT_OPTIONS= -s --rtail-host $HOSTNAME --rtail-web-port 80 --rtail-port 9999 \ndocker run -p 8080:80 -p 514:514/udp -e LOGAGENT_OPTIONS -e LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN  -d --name logagent --restart=always logagent   Set Node.js Memory limits   -e NODE_OPTIONS= --max-old-space-size=200   Please note  Sematext Agent Docker  might be of interest if you like to collect logs, events and metrics from Docker.", 
            "title": "Docker - receive logs via syslog"
        }, 
        {
            "location": "/installation/#install-logagent-as-heroku-log-drain", 
            "text": "Heroku  can forward logs to a  Log Drain    heroku drain:add --app HerokuAppName URL   To receive Heroku logs, logagent-js can be deployed to Heroku. It acts as HTTPS log drain.    Get a free account  apps.sematext.com     Create a  Logsene  App to obtain the Logsene Token  Deploy logagent-js to Heroku     or use the following commands:  git clone https://github.com/sematext/logagent-js.git\n  cd logagent-js\n  heroku login \n  heroku create\n  git push heroku master \n4. Add the the log drain. \n  The URL format is https://loggerAppName.herokuapps.com/LOGSENE_TOKEN\n  Use following command, using the dynamically given name from \"heroku create\".  export LOGSENE_TOKEN=YOUR_LOGSENE_TOKEN\n  heroku drains:add --app YOUR_HEROKU_MAIN_APPLICATION  `heroku info -s | grep web-url | cut -d= -f2`$LOGSENE_TOKEN \nNow you can see your logs in Logsene, define Alert-Queries or use Kibana for Dashboards.    Scale logagent-js service on Heroku   In case of high log volume, scale logagent-js  on demand using   heroku scale web=3", 
            "title": "Install logagent as Heroku log drain"
        }, 
        {
            "location": "/cli-parameters/", 
            "text": "Command Line Parameters for logagent\n\n\n\n\n\n\n\n\nParamater\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-f\n patterns.yml\n\n\nfile with pattern definitions\n\n\n\n\n\n\n-y\n\n\nprints parsed messages in YAML format to stdout\n\n\n\n\n\n\n-p\n\n\npretty json output\n\n\n\n\n\n\n-s\n\n\nsilent, print no logss, only throughput and memory usage on exit\n\n\n\n\n\n\n-t\n token\n\n\nLogsene\n App Token to insert parsed records into Logsene.\n\n\n\n\n\n\n-g\n glob-pattern\n\n\nuse a \nglob\n pattern to watch log files e.g. -g \"{/var/log/\n.log,/Users/stefan/\n/*.log}\"\n\n\n\n\n\n\n--logsene-tmp-dir\n  path\n\n\ndirectory to store buffered logs during network outage\n\n\n\n\n\n\n-u\n UDP_PORT\n\n\nstarts a syslogd UDP listener on the given port to act as syslogd\n\n\n\n\n\n\n-n\n name\n\n\nname for the source only when stdin is used, important to make multi-line patterns working on stdin because the status is tracked by the source name.\n\n\n\n\n\n\n--heroku\n PORT\n\n\nlistens for heroku logs (http drain / framed syslog over http)\n\n\n\n\n\n\n--cfhttp\n PORT\n\n\nlistens for CloudFoundry logs (syslog over http)\n\n\n\n\n\n\n--rtail-port\n\n\nforwards logs via udp to \nrtail\n server\n\n\n\n\n\n\n--rtail-host\n hostname\n\n\nrtail\n server (UI for realtime logs), default: localhost\n\n\n\n\n\n\nlist of files\n, e.g. /var/log/*.log\n\n\nwatched by \ntail-forever\n starting at end of file to watch\n\n\n\n\n\n\n\n\nThe default output is line delimited JSON.\n\n\nCommand Line Examples\n\n\n# Be Evil: parse all logs \n# stream logs to Logsene 1-Click ELK stack \nlogagent -t LOGSENE_TOKEN /var/log/*.log \n# Act as syslog server on UDP and forward messages to Logsene\nlogagent -t LOGSENE_TOKEN -u 1514 \n# Act as syslog server on UDP and write YAML formated messages to console\nlogagent -u 1514 -y  \n\n\n\n\nUse a \nglob\n pattern to build the file list \n\n\nlogagent -t LOGSENE_TOKEN -g \n{/var/log/*.log,/opt/myapp/*.log}\n \n\n\n\n\nWatch selective log output on console by passing logs via stdin and format in YAML\n\n\ntail -f /var/log/access.log | logagent -y \ntail -f /var/log/system.log | logagent -f my_own_patterns.yml  -y \n\n\n\n\nShip logs to rtail and Logsene to view logs in real-time in rtail and store logs in Logsene\n\n\n# rtail don't need to be installed, logagent uses the rtail protocol\nlogagent -t $LOGSENE_TOKEN --rtail-host myrtailserver --rtail-port 9999 /var/log/*.log\n\n\n\n\nLogagent can start the rtail web-server (in-process, saving memory), open browser with http://localhost:8080\n\n\n# logagent has no dependency to rtail, to keep the package small\nsudo npm i rtail -g\nlogagent -s -t $LOGSENE_TOKEN --rtail-web-port 8080 --rtail-port 9999 /var/log/*.log\n\n\n\n\nAnd of course you can combine rtail and Logagent in the traditional way, simply connect both via unix pipes. An example with rtail and Logsene storage and charts:", 
            "title": "Command Line Options"
        }, 
        {
            "location": "/cli-parameters/#command-line-parameters-for-logagent", 
            "text": "Paramater  Description      -f  patterns.yml  file with pattern definitions    -y  prints parsed messages in YAML format to stdout    -p  pretty json output    -s  silent, print no logss, only throughput and memory usage on exit    -t  token  Logsene  App Token to insert parsed records into Logsene.    -g  glob-pattern  use a  glob  pattern to watch log files e.g. -g \"{/var/log/ .log,/Users/stefan/ /*.log}\"    --logsene-tmp-dir   path  directory to store buffered logs during network outage    -u  UDP_PORT  starts a syslogd UDP listener on the given port to act as syslogd    -n  name  name for the source only when stdin is used, important to make multi-line patterns working on stdin because the status is tracked by the source name.    --heroku  PORT  listens for heroku logs (http drain / framed syslog over http)    --cfhttp  PORT  listens for CloudFoundry logs (syslog over http)    --rtail-port  forwards logs via udp to  rtail  server    --rtail-host  hostname  rtail  server (UI for realtime logs), default: localhost    list of files , e.g. /var/log/*.log  watched by  tail-forever  starting at end of file to watch     The default output is line delimited JSON.", 
            "title": "Command Line Parameters for logagent"
        }, 
        {
            "location": "/cli-parameters/#command-line-examples", 
            "text": "# Be Evil: parse all logs \n# stream logs to Logsene 1-Click ELK stack \nlogagent -t LOGSENE_TOKEN /var/log/*.log \n# Act as syslog server on UDP and forward messages to Logsene\nlogagent -t LOGSENE_TOKEN -u 1514 \n# Act as syslog server on UDP and write YAML formated messages to console\nlogagent -u 1514 -y    Use a  glob  pattern to build the file list   logagent -t LOGSENE_TOKEN -g  {/var/log/*.log,/opt/myapp/*.log}    Watch selective log output on console by passing logs via stdin and format in YAML  tail -f /var/log/access.log | logagent -y \ntail -f /var/log/system.log | logagent -f my_own_patterns.yml  -y   Ship logs to rtail and Logsene to view logs in real-time in rtail and store logs in Logsene  # rtail don't need to be installed, logagent uses the rtail protocol\nlogagent -t $LOGSENE_TOKEN --rtail-host myrtailserver --rtail-port 9999 /var/log/*.log  Logagent can start the rtail web-server (in-process, saving memory), open browser with http://localhost:8080  # logagent has no dependency to rtail, to keep the package small\nsudo npm i rtail -g\nlogagent -s -t $LOGSENE_TOKEN --rtail-web-port 8080 --rtail-port 9999 /var/log/*.log  And of course you can combine rtail and Logagent in the traditional way, simply connect both via unix pipes. An example with rtail and Logsene storage and charts:", 
            "title": "Command Line Examples"
        }, 
        {
            "location": "/parser/", 
            "text": "How does the parser work?\n\n\nThe parser detects log formats based on a pattern library (yaml file) and converts it to a JSON Object:\n\n\n\n\nfind matching regex in pattern library\n\n\ntag it with the recognized type\n\n\nextract fields using regex\n\n\nif 'autohash' is enabled, sensitive data is replaced with its sha1 hash code\n\n\nparse dates and detect date format\n  (use 'ts' field for date and time combined) \n\n\ncreate ISO timestamp in '@timestamp' field\n\n\ntransform function to manipulate parsed objects\n\n\nunmatched lines end up with timestamp and original line in the message field\n\n\nJSON lines are parsed, and scanned for @timestamp and time fields (logstash and bunyan format)\n\n\ndefault patterns for many applications (see below)\n\n\nHeroku logs\n\n\n\n\nThe default pattern definition file include already patterns for:\n\n\n\n\nMongoDB, \n\n\nMySQL, \n\n\nNginx, \n\n\nRedis, \n\n\nElasticsearch\n\n\nWebserver (nginx, apache httpd), \n\n\nZookeeper, \n\n\nCassandra, \n\n\nKafka,\n\n\nHBase HDFS Data Node,\n\n\nHBase Region Server,\n\n\nHadoop YARN Node Manager, \n\n\nApache SOLR,\n\n\nvarious Linux/Mac OS X system log files \n\n\n\n\nThe file format is based on \nJS-YAML\n, in short:\n\n\n- - indicates an  array\n- !js/regexp - indicates a JS regular expression\n- !!js/function \n - indicates a JS function \n\n\n\n\nProperties:\n\n\n\n\npatterns - the list of patterns, each pattern starts with \"-\"\n\n\nmatch: A group of patterns for a specific log source\n\n\nregex: a JS regular expression \n\n\nfields: the field list of extracted match groups from the regex\n\n\ntype: the type used in Logsene (Elasticsearch Mapping)\n\n\ndateFormat: the format of the special fields 'ts', if the date format matches, a new field @timestamp is generated\n\n\ntransform: a JS function to manipulate the result of regex and date parsing\n\n\n\n\nExample\n\n\n# Sensitive data can be replaced with a hashcode (sha1)\n# it applies to fields matching the field names by a regular expression\n# Note: this function is not optimized (yet) and might take 10-15% of performance\nautohash: !!js/regexp /user|password|email|credit_card_number|payment_info/i\n# set this to false when authash fields\n# the original line might include sensitive data!\noriginalLine: false\n# activate GeoIP lookup\ngeoIP: true\n# logagent updates geoip db files automatically\n# pls. note write access to this directory is required\nmaxmindDbDir: /tmp/\npatterns: \n  - # APACHE  Web Logs\n  sourceName: httpd\n  match: \n    # Common Log Format\n    - regex:        !!js/regexp /([0-9a-f.:]+)\\s+(-|.+?)\\s+(-|.+?)\\s+\\[([0-9]{2}\\/[a-z]{3}\\/[0-9]{4}\\:[0-9]{2}:[0-9]{2}:[0-9]{2}[^\\]]*)\\] \\\n(\\S+?)\\s(\\S*?)\\s{0,1}(\\S+?)\\\n ([0-9|\\-]+) ([0-9|\\-]+)/i\n      type: apache_access_common\n      fields:       [client_ip,remote_id,user,ts,method,path,http_version,status_code,size]\n      dateFormat: DD/MMM/YYYY:HH:mm:ss ZZ\n      # lookup geoip info for the field client_ip\n      geoIP: client_ip\n      transform: !!js/function \n\n        function (p) {\n          p.message = p.method + ' ' + p.path\n        }\n\n\n\n\nThe default patterns are \nhere\n - contributions are welcome.", 
            "title": "Log Parser and pattern definitions"
        }, 
        {
            "location": "/parser/#how-does-the-parser-work", 
            "text": "The parser detects log formats based on a pattern library (yaml file) and converts it to a JSON Object:   find matching regex in pattern library  tag it with the recognized type  extract fields using regex  if 'autohash' is enabled, sensitive data is replaced with its sha1 hash code  parse dates and detect date format\n  (use 'ts' field for date and time combined)   create ISO timestamp in '@timestamp' field  transform function to manipulate parsed objects  unmatched lines end up with timestamp and original line in the message field  JSON lines are parsed, and scanned for @timestamp and time fields (logstash and bunyan format)  default patterns for many applications (see below)  Heroku logs   The default pattern definition file include already patterns for:   MongoDB,   MySQL,   Nginx,   Redis,   Elasticsearch  Webserver (nginx, apache httpd),   Zookeeper,   Cassandra,   Kafka,  HBase HDFS Data Node,  HBase Region Server,  Hadoop YARN Node Manager,   Apache SOLR,  various Linux/Mac OS X system log files    The file format is based on  JS-YAML , in short:  - - indicates an  array\n- !js/regexp - indicates a JS regular expression\n- !!js/function   - indicates a JS function   Properties:   patterns - the list of patterns, each pattern starts with \"-\"  match: A group of patterns for a specific log source  regex: a JS regular expression   fields: the field list of extracted match groups from the regex  type: the type used in Logsene (Elasticsearch Mapping)  dateFormat: the format of the special fields 'ts', if the date format matches, a new field @timestamp is generated  transform: a JS function to manipulate the result of regex and date parsing", 
            "title": "How does the parser work?"
        }, 
        {
            "location": "/parser/#example", 
            "text": "# Sensitive data can be replaced with a hashcode (sha1)\n# it applies to fields matching the field names by a regular expression\n# Note: this function is not optimized (yet) and might take 10-15% of performance\nautohash: !!js/regexp /user|password|email|credit_card_number|payment_info/i\n# set this to false when authash fields\n# the original line might include sensitive data!\noriginalLine: false\n# activate GeoIP lookup\ngeoIP: true\n# logagent updates geoip db files automatically\n# pls. note write access to this directory is required\nmaxmindDbDir: /tmp/\npatterns: \n  - # APACHE  Web Logs\n  sourceName: httpd\n  match: \n    # Common Log Format\n    - regex:        !!js/regexp /([0-9a-f.:]+)\\s+(-|.+?)\\s+(-|.+?)\\s+\\[([0-9]{2}\\/[a-z]{3}\\/[0-9]{4}\\:[0-9]{2}:[0-9]{2}:[0-9]{2}[^\\]]*)\\] \\ (\\S+?)\\s(\\S*?)\\s{0,1}(\\S+?)\\  ([0-9|\\-]+) ([0-9|\\-]+)/i\n      type: apache_access_common\n      fields:       [client_ip,remote_id,user,ts,method,path,http_version,status_code,size]\n      dateFormat: DD/MMM/YYYY:HH:mm:ss ZZ\n      # lookup geoip info for the field client_ip\n      geoIP: client_ip\n      transform: !!js/function  \n        function (p) {\n          p.message = p.method + ' ' + p.path\n        }  The default patterns are  here  - contributions are welcome.", 
            "title": "Example"
        }, 
        {
            "location": "/nodejs-api/", 
            "text": "Install logagent as local module and save the dependency to your package.json\n\n\nnpm i logagent-js --save\n\n\n\n\nUse the Logparser module in your source code\n\n\nvar Logparser = require('logagent-js')\nvar lp = new Logparser('./patterns.yml')\nlp.parseLine('log message', 'source name', function (err, data) {\n    if(err) {\n      console.log('line did not match with any pattern')\n    }\n    console.log(JSON.stringify(data))\n})\n\n\n\n\nTo test patterns or convert logs from text to JSON use the command line tool 'logagent'. It reads from stdin and outputs line delimited JSON (or pretty JSON or YAML) to the console. In addtion it can forward the parsed objects directly to \nLogsene\n.\n\n\nTest your patterns:\n\n\ncat myapp.log | bin/logagent -y -n myapp -f mypatterns.yml", 
            "title": "Node.js API"
        }
    ]
}